-------------------------------------------------------------------------------------------------------------------------------------------
      name:  <unnamed>
       log:  /Users/sokbaelee/Dropbox/Persuasion/JPE/Replication Files/scripts/logs/2022.11.11-08.11.39.log.txt
  log type:  text
 opened on:  11 Nov 2022, 08:11:39

. 
. di "Begin date and time: $S_DATE $S_TIME"
Begin date and time: 11 Nov 2022 08:11:39

. di "Stata version: `c(stata_version)'"
Stata version: 17

. di "Updated as of: `c(born_date)'"
Updated as of: 23 Aug 2022

. di "Variant:       `=cond( c(MP),"MP",cond(c(SE),"SE",c(flavor)) )'"
Variant:       MP

. di "Processors:    `c(processors)'"
Processors:    4

. di "OS:            `c(os)' `c(osdtl)'"
OS:            MacOSX 12.5.1

. di "Machine type:  `c(machine_type)'"
Machine type:  Mac (Apple Silicon)

. 
. * Stata version control
. version 16

. 
. * Create directories for output files
. cap mkdir "$Persuasion/results"

. 
. **********************
. * Run analysis
. **********************
. * TABLE 1. Persuasion Rates: Papers on Voter Turnout
. *do "$Persuasion/scripts/table1.do"
. 
. * Effects of Uncensored Media: Revisiting Chen and Yang (2019)
. *   To generate the dataset "ChenYang2019.dta", it is necessary to run CY19_data.do 
. *   after downloading the original dataset from 
. *   the AER webpage at https://www.aeaweb.org/articles?id=10.1257/aer.20171765
. *   and storing them at "$Persuasion/data/ChenYang2019".
. *   As the dataset is already created and stored at "$Persuasion/data/ChenYang2019", 
. *   the do file is commented below.
. *do "$Persuasion/scripts/CY19_data.do"
. *   TABLE 2. Persuasion Rates of Exposure to Uncensored Internet
. *do "$Persuasion/scripts/table2.do"
. 
. * Effects of Political News: Revisting Gerber, Karlan, and Bergan (2009) 
. *   TABLE 3. Summary Statistics of the GKB Data
. *do "$Persuasion/scripts/table3.do"
. *   TABLE 4. Estimates of the Key Parameters
. *do "$Persuasion/scripts/table4.do"
. 
. *       TABLE D1. Persuasion Rates: Fox News Effects
. *do "$Persuasion/scripts/tableD1.do"
. 
. *       FIGURE D1. Estimates of Marginal and Average Persuasion Rates
. do "$Persuasion/scripts/figureD1.do"

. ************
. * SCRIPT:   figureD1.do
. * PURPOSE:  Creates Figure D1
. *
. * ACKNOWLEDGMENT
. *       The orginal dataset "NTV_Individual_Data.dta" is from Enikolopov, Petrova, and Zhuravskaya (AER, 2011).
. ************
. 
. use "$Persuasion/data/EnikolopovPetrovaZhuravskaya2011/NTV_Individual_Data.dta", clear

. 
. local basic = "logpop98 wage98_ln"

. local sociodem = "male age educ1 married consump"

. 
. local party_list = "Unity OVR"

. 
. *** create outcome variables based on directional treatment ***
. 
. gen y_vote_Unity = 0

. replace y_vote_Unity = 1 if vote_Unity == 0   
(993 real changes made)

. 
. gen y_vote_OVR = 0

. replace y_vote_OVR = 1 if vote_OVR == 1   
(166 real changes made)

. 
. *** predict the exposure rate, that is, e(X,Z) = P(T=1|X,Z) ***
. *** specification: linear in Z and X ***
. 
. probit  Watches_NTV_1999 tvmaxtveloss5050powerA `sociodem' `basic' [pweight=kishweig]

Iteration 0:   log pseudolikelihood = -809.06705  
Iteration 1:   log pseudolikelihood = -741.86673  
Iteration 2:   log pseudolikelihood =  -741.6003  
Iteration 3:   log pseudolikelihood = -741.60028  

Probit regression                                       Number of obs =  1,185
                                                        Wald chi2(8)  = 105.94
                                                        Prob > chi2   = 0.0000
Log pseudolikelihood = -741.60028                       Pseudo R2     = 0.0834

----------------------------------------------------------------------------------------
                       |               Robust
      Watches_NTV_1999 | Coefficient  std. err.      z    P>|z|     [95% conf. interval]
-----------------------+----------------------------------------------------------------
tvmaxtveloss5050powerA |   .0068679   .0011649     5.90   0.000     .0045848    .0091511
                  male |   .2299747   .0893844     2.57   0.010     .0547845    .4051648
                   age |  -.0063456   .0029081    -2.18   0.029    -.0120454   -.0006458
                 educ1 |   .2459444   .1188836     2.07   0.039     .0129369    .4789519
               married |   .0520022   .0908934     0.57   0.567    -.1261455    .2301499
               consump |   .0711412   .0341425     2.08   0.037     .0042231    .1380594
              logpop98 |  -.2162026    .045017    -4.80   0.000    -.3044343    -.127971
             wage98_ln |   .4838216   .1418335     3.41   0.001     .2058331    .7618101
                 _cons |  -2.154867   .9164043    -2.35   0.019    -3.950986   -.3587474
----------------------------------------------------------------------------------------

. predict phat
(option pr assumed; Pr(Watches_NTV_1999))
(4,658 missing values generated)

. 
. ***
. 
. foreach party in `party_list' {
  2. 
.         * generate Y*(1-T)
.     gen notwatch_vote_`party' = 0
  3.         replace notwatch_vote_`party' = 1 if y_vote_`party' == 1 & Watches_NTV_1999==0
  4.         
.         * linear probability model of Y given X and e(X,Z)
.         * specification: linear in X and cubic in e(X,Z), while interacting some of X and e(X,Z)
. *       reg y_vote_`party' `sociodem' `basic' ///
> *                       c.phat c.phat#c.phat c.phat#c.phat#c.phat ///
> *                       c.phat#i.male c.phat#c.age c.phat#i.educ1 c.phat#i.married c.phat#c.consump ///
> *                       [pweight=kishweig]
.                         
.         reg y_vote_`party' `sociodem' `basic' ///
>                         c.phat c.phat#c.phat ///
>                         [pweight=kishweig]              
  5.         
.         margins [pweight=kishweig], dydx(phat) at(phat = (0.01(0.01)0.99))
  6. 
. }
(313 real changes made)
(sum of wgt is 1,312.04910933971)

Linear regression                               Number of obs     =      1,300
                                                F(9, 1290)        =       6.74
                                                Prob > F          =     0.0000
                                                R-squared         =     0.0484
                                                Root MSE          =     .48776

-------------------------------------------------------------------------------
              |               Robust
 y_vote_Unity | Coefficient  std. err.      t    P>|t|     [95% conf. interval]
--------------+----------------------------------------------------------------
         male |  -.0293914   .0344439    -0.85   0.394    -.0969635    .0381808
          age |   .0071963   .0010176     7.07   0.000        .0052    .0091926
        educ1 |    .047958   .0451079     1.06   0.288    -.0405349    .1364509
      married |   .0351004   .0326513     1.08   0.283    -.0289551     .099156
      consump |  -.0077279   .0130409    -0.59   0.554    -.0333116    .0178559
     logpop98 |   .0036366    .014314     0.25   0.799    -.0244445    .0317178
    wage98_ln |  -.1701584   .0623922    -2.73   0.006    -.2925597   -.0477572
         phat |  -.5063025   .5965454    -0.85   0.396    -1.676608    .6640031
              |
c.phat#c.phat |   .8761134   .5187216     1.69   0.091    -.1415172    1.893744
              |
        _cons |   1.386847   .4193568     3.31   0.001     .5641513    2.209544
-------------------------------------------------------------------------------

Average marginal effects                                 Number of obs = 1,300
Model VCE: Robust

Expression: Linear prediction, predict()
dy/dx wrt:  phat
1._at:  phat = .01
2._at:  phat = .02
3._at:  phat = .03
4._at:  phat = .04
5._at:  phat = .05
6._at:  phat = .06
7._at:  phat = .07
8._at:  phat = .08
9._at:  phat = .09
10._at: phat =  .1
11._at: phat = .11
12._at: phat = .12
13._at: phat = .13
14._at: phat = .14
15._at: phat = .15
16._at: phat = .16
17._at: phat = .17
18._at: phat = .18
19._at: phat = .19
20._at: phat =  .2
21._at: phat = .21
22._at: phat = .22
23._at: phat = .23
24._at: phat = .24
25._at: phat = .25
26._at: phat = .26
27._at: phat = .27
28._at: phat = .28
29._at: phat = .29
30._at: phat =  .3
31._at: phat = .31
32._at: phat = .32
33._at: phat = .33
34._at: phat = .34
35._at: phat = .35
36._at: phat = .36
37._at: phat = .37
38._at: phat = .38
39._at: phat = .39
40._at: phat =  .4
41._at: phat = .41
42._at: phat = .42
43._at: phat = .43
44._at: phat = .44
45._at: phat = .45
46._at: phat = .46
47._at: phat = .47
48._at: phat = .48
49._at: phat = .49
50._at: phat =  .5
51._at: phat = .51
52._at: phat = .52
53._at: phat = .53
54._at: phat = .54
55._at: phat = .55
56._at: phat = .56
57._at: phat = .57
58._at: phat = .58
59._at: phat = .59
60._at: phat =  .6
61._at: phat = .61
62._at: phat = .62
63._at: phat = .63
64._at: phat = .64
65._at: phat = .65
66._at: phat = .66
67._at: phat = .67
68._at: phat = .68
69._at: phat = .69
70._at: phat =  .7
71._at: phat = .71
72._at: phat = .72
73._at: phat = .73
74._at: phat = .74
75._at: phat = .75
76._at: phat = .76
77._at: phat = .77
78._at: phat = .78
79._at: phat = .79
80._at: phat =  .8
81._at: phat = .81
82._at: phat = .82
83._at: phat = .83
84._at: phat = .84
85._at: phat = .85
86._at: phat = .86
87._at: phat = .87
88._at: phat = .88
89._at: phat = .89
90._at: phat =  .9
91._at: phat = .91
92._at: phat = .92
93._at: phat = .93
94._at: phat = .94
95._at: phat = .95
96._at: phat = .96
97._at: phat = .97
98._at: phat = .98
99._at: phat = .99

------------------------------------------------------------------------------
             |            Delta-method
             |      dy/dx   std. err.      t    P>|t|     [95% conf. interval]
-------------+----------------------------------------------------------------
phat         |
         _at |
          1  |  -.4887802   .5865705    -0.83   0.405    -1.639517    .6619566
          2  |  -.4712579   .5766098    -0.82   0.414    -1.602454    .6599378
          3  |  -.4537357   .5666638    -0.80   0.423    -1.565419    .6579481
          4  |  -.4362134   .5567335    -0.78   0.433    -1.528416     .655989
          5  |  -.4186911   .5468197    -0.77   0.444    -1.491445    .6540624
          6  |  -.4011689   .5369233    -0.75   0.455    -1.454508    .6521698
          7  |  -.3836466   .5270453    -0.73   0.467    -1.417607    .6503134
          8  |  -.3661243   .5171868    -0.71   0.479    -1.380744     .648495
          9  |  -.3486021   .5073487    -0.69   0.492    -1.343921    .6467171
         10  |  -.3310798   .4975325    -0.67   0.506    -1.307141    .6449819
         11  |  -.3135575   .4877394    -0.64   0.520    -1.270407     .643292
         12  |  -.2960353   .4779709    -0.62   0.536    -1.233721    .6416502
         13  |   -.278513   .4682284    -0.59   0.552    -1.197086    .6400596
         14  |  -.2609907   .4585136    -0.57   0.569    -1.160505    .6385234
         15  |  -.2434684   .4488283    -0.54   0.588    -1.123982    .6370451
         16  |  -.2259462   .4391746    -0.51   0.607    -1.087521    .6356286
         17  |  -.2084239   .4295544    -0.49   0.628    -1.051126    .6342779
         18  |  -.1909016   .4199702    -0.45   0.650    -1.014801    .6329978
         19  |  -.1733794   .4104243    -0.42   0.673    -.9785518     .631793
         20  |  -.1558571   .4009197    -0.39   0.698    -.9423832     .630669
         21  |  -.1383349   .3914592    -0.35   0.724    -.9063014    .6296316
         22  |  -.1208126   .3820462    -0.32   0.752    -.8703125    .6286874
         23  |  -.1032903   .3726842    -0.28   0.782    -.8344239    .6278433
         24  |  -.0857681   .3633772    -0.24   0.813    -.7986432     .627107
         25  |  -.0682458   .3541295    -0.19   0.847    -.7629788    .6264872
         26  |  -.0507235    .344946    -0.15   0.883    -.7274402    .6259931
         27  |  -.0332012   .3358318    -0.10   0.921    -.6920376    .6256351
         28  |   -.015679   .3267928    -0.05   0.962    -.6567826    .6254246
         29  |   .0018433   .3178353     0.01   0.995    -.6216875    .6253741
         30  |   .0193656   .3089665     0.06   0.950    -.5867664    .6254976
         31  |   .0368878   .3001943     0.12   0.902    -.5520347    .6258104
         32  |   .0544101   .2915273     0.19   0.852    -.5175095    .6263297
         33  |   .0719324   .2829752     0.25   0.799    -.4832097    .6270744
         34  |   .0894546   .2745488     0.33   0.745    -.4491564    .6280657
         35  |   .1069769   .2662599     0.40   0.688    -.4153731    .6293269
         36  |   .1244992   .2581219     0.48   0.630    -.3818856     .630884
         37  |   .1420214   .2501495     0.57   0.570     -.348723    .6327659
         38  |   .1595437    .242359     0.66   0.510    -.3159173    .6350046
         39  |   .1770659   .2347684     0.75   0.451    -.2835039    .6376358
         40  |   .1945882   .2273979     0.86   0.392    -.2515221    .6406986
         41  |   .2121105   .2202696     0.96   0.336    -.2200154    .6442364
         42  |   .2296327   .2134077     1.08   0.282    -.1890314    .6482969
         43  |   .2471551   .2068386     1.19   0.232    -.1586219     .652932
         44  |   .2646773   .2005912     1.32   0.187    -.1288435    .6581981
         45  |   .2821996   .1946966     1.45   0.147     -.099757    .6641562
         46  |   .2997219   .1891875     1.58   0.113     -.071427    .6708707
         47  |   .3172441   .1840987     1.72   0.085    -.0439215    .6784097
         48  |   .3347664   .1794658     1.87   0.062    -.0173106    .6868433
         49  |   .3522887   .1753252     2.01   0.045     .0083349    .6962424
         50  |   .3698109   .1717123     2.15   0.031      .032945    .7066768
         51  |   .3873332    .168661     2.30   0.022     .0564531    .7182132
         52  |   .4048554   .1662024     2.44   0.015     .0787987    .7309121
         53  |   .4223777   .1643631     2.57   0.010     .0999295    .7448259
         54  |      .4399   .1631638     2.70   0.007     .1198045    .7599955
         55  |   .4574223   .1626189     2.81   0.005     .1383958    .7764488
         56  |   .4749445   .1627349     2.92   0.004     .1556905    .7941986
         57  |   .4924668   .1635103     3.01   0.003     .1716914    .8132421
         58  |    .509989    .164936     3.09   0.002     .1864168    .8335612
         59  |   .5275113   .1669952     3.16   0.002     .1998994    .8551232
         60  |   .5450336   .1696648     3.21   0.001     .2121844    .8778829
         61  |   .5625559   .1729167     3.25   0.001     .2233272    .9017846
         62  |   .5800781   .1767186     3.28   0.001     .2333908    .9267654
         63  |   .5976004   .1810359     3.30   0.001     .2424434    .9527574
         64  |   .6151226   .1858327     3.31   0.001     .2505552      .97969
         65  |   .6326449   .1910728     3.31   0.001     .2577973    1.007492
         66  |   .6501672    .196721     3.31   0.001     .2642391    1.036095
         67  |   .6676895    .202743     3.29   0.001     .2699473    1.065432
         68  |   .6852117   .2091065     3.28   0.001     .2749856    1.095438
         69  |    .702734   .2157814     3.26   0.001      .279413    1.126055
         70  |   .7202562   .2227397     3.23   0.001     .2832845    1.157228
         71  |   .7377785   .2299556     3.21   0.001     .2866506    1.188906
         72  |   .7553009   .2374056     3.18   0.002     .2895574    1.221044
         73  |   .7728231   .2450685     3.15   0.002     .2920467      1.2536
         74  |   .7903454   .2529247     3.12   0.002     .2941564    1.286534
         75  |   .8078676    .260957     3.10   0.002      .295921    1.319814
         76  |   .8253899   .2691495     3.07   0.002     .2973712    1.353409
         77  |   .8429121    .277488     3.04   0.002     .2985349    1.387289
         78  |   .8604344   .2859597     3.01   0.003     .2994372    1.421431
         79  |   .8779567   .2945533     2.98   0.003     .3001007    1.455813
         80  |    .895479   .3032583     2.95   0.003     .3005455    1.490412
         81  |   .9130012   .3120653     2.93   0.003     .3007901    1.525212
         82  |   .9305235    .320966     2.90   0.004     .3008509    1.560196
         83  |   .9480457   .3299528     2.87   0.004     .3007428    1.595349
         84  |    .965568   .3390189     2.85   0.004     .3004792    1.630657
         85  |   .9830903   .3481581     2.82   0.005     .3000722    1.666108
         86  |   1.000613   .3573647     2.80   0.005     .2995329    1.701692
         87  |   1.018135   .3666336     2.78   0.006     .2988713    1.737398
         88  |   1.035657   .3759604     2.75   0.006     .2980963    1.773218
         89  |   1.053179   .3853407     2.73   0.006     .2972162    1.809142
         90  |   1.070702   .3947707     2.71   0.007     .2962386    1.845165
         91  |   1.088224   .4042471     2.69   0.007     .2951701    1.881278
         92  |   1.105746   .4137665     2.67   0.008     .2940172    1.917475
         93  |   1.123268   .4233261     2.65   0.008     .2927854    1.953751
         94  |   1.140791   .4329232     2.64   0.009       .29148    1.990101
         95  |   1.158313   .4425554     2.62   0.009     .2901057     2.02652
         96  |   1.175835   .4522204     2.60   0.009     .2886671    2.063003
         97  |   1.193358   .4619163     2.58   0.010     .2871681    2.099547
         98  |    1.21088    .471641     2.57   0.010     .2856124    2.136147
         99  |   1.228402   .4813928     2.55   0.011     .2840035    2.172801
------------------------------------------------------------------------------
(30 real changes made)
(sum of wgt is 1,312.04910933971)

Linear regression                               Number of obs     =      1,300
                                                F(9, 1290)        =       1.54
                                                Prob > F          =     0.1286
                                                R-squared         =     0.0129
                                                Root MSE          =     .25127

-------------------------------------------------------------------------------
              |               Robust
   y_vote_OVR | Coefficient  std. err.      t    P>|t|     [95% conf. interval]
--------------+----------------------------------------------------------------
         male |  -.0457998   .0174675    -2.62   0.009    -.0800676    -.011532
          age |   .0011181    .000673     1.66   0.097    -.0002021    .0024383
        educ1 |  -.0080977   .0264699    -0.31   0.760    -.0600266    .0438311
      married |   .0117132   .0159586     0.73   0.463    -.0195943    .0430208
      consump |  -.0020105    .006912    -0.29   0.771    -.0155706    .0115495
     logpop98 |  -.0016714   .0077407    -0.22   0.829    -.0168571    .0135143
    wage98_ln |  -.0458474   .0350585    -1.31   0.191    -.1146254    .0229305
         phat |   .3878462   .2901241     1.34   0.182    -.1813207     .957013
              |
c.phat#c.phat |  -.1530891   .2371551    -0.65   0.519    -.6183412     .312163
              |
        _cons |   .1975847   .2341658     0.84   0.399    -.2618028    .6569722
-------------------------------------------------------------------------------

Average marginal effects                                 Number of obs = 1,300
Model VCE: Robust

Expression: Linear prediction, predict()
dy/dx wrt:  phat
1._at:  phat = .01
2._at:  phat = .02
3._at:  phat = .03
4._at:  phat = .04
5._at:  phat = .05
6._at:  phat = .06
7._at:  phat = .07
8._at:  phat = .08
9._at:  phat = .09
10._at: phat =  .1
11._at: phat = .11
12._at: phat = .12
13._at: phat = .13
14._at: phat = .14
15._at: phat = .15
16._at: phat = .16
17._at: phat = .17
18._at: phat = .18
19._at: phat = .19
20._at: phat =  .2
21._at: phat = .21
22._at: phat = .22
23._at: phat = .23
24._at: phat = .24
25._at: phat = .25
26._at: phat = .26
27._at: phat = .27
28._at: phat = .28
29._at: phat = .29
30._at: phat =  .3
31._at: phat = .31
32._at: phat = .32
33._at: phat = .33
34._at: phat = .34
35._at: phat = .35
36._at: phat = .36
37._at: phat = .37
38._at: phat = .38
39._at: phat = .39
40._at: phat =  .4
41._at: phat = .41
42._at: phat = .42
43._at: phat = .43
44._at: phat = .44
45._at: phat = .45
46._at: phat = .46
47._at: phat = .47
48._at: phat = .48
49._at: phat = .49
50._at: phat =  .5
51._at: phat = .51
52._at: phat = .52
53._at: phat = .53
54._at: phat = .54
55._at: phat = .55
56._at: phat = .56
57._at: phat = .57
58._at: phat = .58
59._at: phat = .59
60._at: phat =  .6
61._at: phat = .61
62._at: phat = .62
63._at: phat = .63
64._at: phat = .64
65._at: phat = .65
66._at: phat = .66
67._at: phat = .67
68._at: phat = .68
69._at: phat = .69
70._at: phat =  .7
71._at: phat = .71
72._at: phat = .72
73._at: phat = .73
74._at: phat = .74
75._at: phat = .75
76._at: phat = .76
77._at: phat = .77
78._at: phat = .78
79._at: phat = .79
80._at: phat =  .8
81._at: phat = .81
82._at: phat = .82
83._at: phat = .83
84._at: phat = .84
85._at: phat = .85
86._at: phat = .86
87._at: phat = .87
88._at: phat = .88
89._at: phat = .89
90._at: phat =  .9
91._at: phat = .91
92._at: phat = .92
93._at: phat = .93
94._at: phat = .94
95._at: phat = .95
96._at: phat = .96
97._at: phat = .97
98._at: phat = .98
99._at: phat = .99

------------------------------------------------------------------------------
             |            Delta-method
             |      dy/dx   std. err.      t    P>|t|     [95% conf. interval]
-------------+----------------------------------------------------------------
phat         |
         _at |
          1  |   .3847844   .2856147     1.35   0.178    -.1755359    .9451047
          2  |   .3817226    .281113     1.36   0.175    -.1697662    .9332114
          3  |   .3786608   .2766194     1.37   0.171    -.1640124     .921334
          4  |    .375599   .2721342     1.38   0.168    -.1582751    .9094732
          5  |   .3725373   .2676579     1.39   0.164    -.1525553    .8976299
          6  |   .3694755    .263191     1.40   0.161    -.1468539    .8858048
          7  |   .3664137   .2587339     1.42   0.157    -.1411717    .8739991
          8  |   .3633519   .2542872     1.43   0.153    -.1355098    .8622137
          9  |   .3602901   .2498513     1.44   0.150    -.1298694    .8504496
         10  |   .3572283    .245427     1.46   0.146    -.1242514    .8387081
         11  |   .3541666   .2410147     1.47   0.142    -.1186573    .8269904
         12  |   .3511048   .2366153     1.48   0.138    -.1130882    .8152978
         13  |    .348043   .2322294     1.50   0.134    -.1075457    .8036318
         14  |   .3449812   .2278578     1.51   0.130    -.1020313    .7919938
         15  |   .3419194   .2235014     1.53   0.126    -.0965466    .7803855
         16  |   .3388577    .219161     1.55   0.122    -.0910934    .7688088
         17  |   .3357959   .2148377     1.56   0.118    -.0856736    .7572654
         18  |   .3327341   .2105324     1.58   0.114    -.0802893    .7457575
         19  |   .3296723   .2062463     1.60   0.110    -.0749427    .7342873
         20  |   .3266105   .2019807     1.62   0.106    -.0696361    .7228572
         21  |   .3235487   .1977368     1.64   0.102    -.0643722    .7114697
         22  |    .320487   .1935161     1.66   0.098    -.0591538    .7001278
         23  |   .3174252   .1893202     1.68   0.094     -.053984    .6888343
         24  |   .3143634   .1851506     1.70   0.090    -.0488659    .6775927
         25  |   .3113016   .1810093     1.72   0.086    -.0438033    .6664065
         26  |   .3082398   .1768983     1.74   0.082       -.0388    .6552797
         27  |    .305178   .1728196     1.77   0.078    -.0338602    .6442163
         28  |   .3021163   .1687756     1.79   0.074    -.0289885     .633221
         29  |   .2990545    .164769     1.81   0.070      -.02419     .622299
         30  |   .2959927   .1608024     1.84   0.066    -.0194701    .6114555
         31  |   .2929309   .1568789     1.87   0.062    -.0148348    .6006967
         32  |   .2898691   .1530019     1.89   0.058    -.0102906    .5900289
         33  |   .2868074   .1491749     1.92   0.055    -.0058446    .5794593
         34  |   .2837456   .1454019     1.95   0.051    -.0015046    .5689957
         35  |   .2806838   .1416873     1.98   0.048     .0027211    .5586465
         36  |    .277622   .1380356     2.01   0.045     .0068231     .548421
         37  |   .2745602   .1344522     2.04   0.041     .0107913    .5383291
         38  |   .2714985   .1309425     2.07   0.038     .0146149     .528382
         39  |   .2684367   .1275126     2.11   0.035     .0182818    .5185916
         40  |   .2653749   .1241693     2.14   0.033      .021779    .5089707
         41  |   .2623131   .1209195     2.17   0.030     .0250926    .4995336
         42  |   .2592513   .1177712     2.20   0.028     .0282072    .4902955
         43  |   .2561895   .1147326     2.23   0.026     .0311065    .4812725
         44  |   .2531278   .1118127     2.26   0.024      .033773    .4724825
         45  |    .250066   .1090211     2.29   0.022      .036188     .463944
         46  |   .2470042   .1063677     2.32   0.020     .0383315    .4556768
         47  |   .2439424   .1038633     2.35   0.019     .0401829    .4477019
         48  |   .2408806   .1015188     2.37   0.018     .0417206    .4400407
         49  |   .2378188   .0993456     2.39   0.017     .0429222    .4327155
         50  |   .2347571   .0973551     2.41   0.016     .0437653    .4257488
         51  |   .2316953   .0955588     2.42   0.015     .0442275    .4191631
         52  |   .2286335   .0939678     2.43   0.015      .044287      .41298
         53  |   .2255717   .0925927     2.44   0.015     .0439229    .4072206
         54  |   .2225099   .0914432     2.43   0.015     .0431162    .4019036
         55  |   .2194481   .0905279     2.42   0.015       .04185    .3970463
         56  |   .2163864    .089854     2.41   0.016     .0401103    .3926624
         57  |   .2133246   .0894269     2.39   0.017     .0378864    .3887628
         58  |   .2102628   .0892502     2.36   0.019     .0351713    .3853543
         59  |    .207201   .0893254     2.32   0.021     .0319621      .38244
         60  |   .2041392   .0896518     2.28   0.023       .02826    .3800185
         61  |   .2010775   .0902267     2.23   0.026     .0240704    .3780845
         62  |   .1980157   .0910453     2.17   0.030     .0194025    .3766289
         63  |   .1949539   .0921013     2.12   0.034     .0142691    .3756387
         64  |   .1918921   .0933865     2.05   0.040      .008686    .3750982
         65  |   .1888303   .0948917     1.99   0.047     .0026714    .3749892
         66  |   .1857685   .0966065     1.92   0.055    -.0037545    .3752915
         67  |   .1827068     .09852     1.85   0.064    -.0105701    .3759837
         68  |    .179645   .1006208     1.79   0.074    -.0177534    .3770434
         69  |   .1765832   .1028976     1.72   0.086    -.0252817    .3784481
         70  |   .1735214   .1053388     1.65   0.100    -.0331327    .3801756
         71  |   .1704596   .1079334     1.58   0.115    -.0412846    .3822039
         72  |   .1673978   .1106705     1.51   0.131    -.0497161    .3845118
         73  |   .1643361   .1135399     1.45   0.148    -.0584069    .3870791
         74  |   .1612743   .1165317     1.38   0.167    -.0673381    .3898867
         75  |   .1582125   .1196368     1.32   0.186    -.0764914    .3929165
         76  |   .1551507   .1228465     1.26   0.207    -.0858502    .3961517
         77  |    .152089    .126153     1.21   0.228    -.0953987    .3995766
         78  |   .1490272   .1295488     1.15   0.250    -.1051223    .4031766
         79  |   .1459654   .1330271     1.10   0.273    -.1150077    .4069385
         80  |   .1429036   .1365815     1.05   0.296    -.1250426    .4108497
         81  |   .1398418   .1402062     1.00   0.319    -.1352154     .414899
         82  |     .13678    .143896     0.95   0.342    -.1455159     .419076
         83  |   .1337183    .147646     0.91   0.365    -.1559344    .4233709
         84  |   .1306565   .1514517     0.86   0.388    -.1664622    .4277751
         85  |   .1275947    .155309     0.82   0.411    -.1770913    .4322806
         86  |   .1245329   .1592142     0.78   0.434    -.1878142      .43688
         87  |   .1214711   .1631637     0.74   0.457    -.1986242    .4415665
         88  |   .1184093   .1671546     0.71   0.479    -.2095153     .446334
         89  |   .1153476   .1711838     0.67   0.501    -.2204816    .4511767
         90  |   .1122858   .1752488     0.64   0.522     -.231518    .4560896
         91  |    .109224   .1793471     0.61   0.543    -.2426199    .4610679
         92  |   .1061622   .1834764     0.58   0.563    -.2537826    .4661071
         93  |   .1031004   .1876348     0.55   0.583    -.2650023    .4712032
         94  |   .1000387   .1918203     0.52   0.602    -.2762753    .4763526
         95  |   .0969769   .1960312     0.49   0.621     -.287598    .4815517
         96  |   .0939151   .2002659     0.47   0.639    -.2989674    .4867976
         97  |   .0908533   .2045229     0.44   0.657    -.3103807    .4920873
         98  |   .0877915   .2088009     0.42   0.674     -.321835    .4974181
         99  |   .0847297   .2130986     0.40   0.691     -.333328    .5027875
------------------------------------------------------------------------------

. 
. 
end of do-file

. 
. *       TABLE E1. Persuasive Effect by Treatment in Landry et al. (2006)
. *do "$Persuasion/scripts/tableE1.do"
. *       TABLE E2. Persuasive Effect by Treatment in DLM
. *do "$Persuasion/scripts/tableE2.do"
. 
. *       TABLE H1. Persuasion Rates: NTV Effects Using a Binary Instrument
. *do "$Persuasion/scripts/tableH1.do"
. 
. 
. 
. 
. * End log
. di "End date and time: $S_DATE $S_TIME"
End date and time: 11 Nov 2022 08:11:41

. log close
      name:  <unnamed>
       log:  /Users/sokbaelee/Dropbox/Persuasion/JPE/Replication Files/scripts/logs/2022.11.11-08.11.39.log.txt
  log type:  text
 closed on:  11 Nov 2022, 08:11:41
-------------------------------------------------------------------------------------------------------------------------------------------
